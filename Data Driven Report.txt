# MNIST assignment report 
## Feature Extraction 
When it comes to feature extraction I used 3 techniques: normalisation, 1-dimensional gaussian blur and PCA.
The motive behind normalisation is because it reduces the effects of “outliers pixels” within the train and test images. I normalised the images by taking away the mean of the images from the images.
The motive behind 1-dimensional gaussian blur was to reduce the noise in the images and smooth out the input images. I have fine-tuned my model many times and I have found that best accuracy scores came from setting my sigma value to 5.3. The way I decided to implement what it is my understanding of 1-dimensional gaussian blur is by convolving the images along the rows and then columns. 
The motive behind PCA, is to reduce the time and load computation of my program. The way I implemented PCA is by calculating the covariance matrix from the normalised train images. Once calculated I then used them to find the eigen values and vectors and then sort them in descending order. Then, I was trying to see how many eigen values I needed to ensure that the ratio between variances was at least 99.9%. And use that to get the top features that I want to then use and project it onto the test and train images before returning them. I have obviously tried different variance threshold using a runner files and different values for k and sigma, which led me to using the values as they gave me overall the best results. I tried incorporating LDA on the PCA reduced images, before I thought of using 1-dimensional gaussian blur, but that significantly decreased my noise test score, and only marginally increased my mask accuracy score.
## Classifier Design 
The classifier I used is weighted KNN with cosine distance. The reason is because CNN worked okay but included the outliers or train images that were too far from the actual label. So, I decided to use KNN to limit the influence from these outliers. I tried using Euclidean and Manhattan distances each and their weighted combination, but cosine distance gave me better results. I think this is because cosine focuses more on the shapes of the numbers than how much space they occupy in relation to the image space. I then decided to implement weights to my KNN as closer “matches” should have more influence over further ones, and it did give me better results. At one point I even tried using divergence but that went terribly wrong. The way my weighted KNN works is that for every test image in images it first normalised it and then calculates the cosine distance between it and all of the train images, and then uses np.argpartition to get the k closest distances. I then apply weights to distances by inverting them. After that I got the labels for the k train images that have been picked and carried a weighted voting to determine a fair prediction for a label and added that to a list of predictions. Once the last test image has been processed, I then returned the predictions.
## Performance 
Model loaded from trained_model.pkl
Model loaded from principal_components
Accuracy on noise_test set: 99.00%
Model loaded from principal_components
Accuracy on mask_test set: 97.00% 
## Analysis of Results  
Applying gaussian blur significantly improved my mask accuracy and fairly improve my noise accuracy score thanks to its effect of reducing noise in the images and smoothing out the masks’ sharp edges.
The use of variance threshold and cumulative variance helped me get better results as I knew how much difference in variance from the original raw image data has been lost, which help me get better results on both tests especially on the noise image tests.
Applying cosine distance instead of Euclidean, Manhattan or any of them combined or weighted combined, gave me better results which I think its due to the fact that both Manhattan and Euclidean distances rely on the size of the values and how big the difference between values are, so when I normalised both train and tests images twice, I saw the reason why I got worse scores. I even tried to convert from cosine into Euclidean and use this new Euclidean distance to try and get better scores but that made it worse.
Applying weights made it so that closer neighbours add more influence over the predictions as opposed to using just the mode of the k closest labels or using the first closest neighbour. This increased my accuracy scores on both tests yet again.
Applying PCA to reduce the number of pixels made my runtime a lot faster and increased the accuracy scores as the non-important pixels were removed (that otherwise negatively impacted the way my classifier predicted the label of a test image).

